\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{Irshad2014}
\citation{Yamaguchi2012}
\citation{Torralba2010}
\citation{Russakovsky2015}
\citation{bell15minc}
\citation{Everingham15}
\citation{Torralba2010}
\citation{bell15minc}
\citation{Lin2012}
\citation{AdrianaKovashka2016}
\citation{Cabezas2015}
\citation{Sameki2015}
\citation{Sorokin2008}
\citation{Dawid1979}
\newlabel{sec:intro}{{1}{1}{Introduction}{section.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Pink is the segmentation from individual workers. Blue solid line delineates the ground truth. The red boxed pointer indicates the task of interest shown to users. Examples demonstrating common error patterns among crowdsourced image segmentation, including 1) annotations on the wrong semantic object, 2) ambiguity in regional inclusion and exclusion, and 3) imprecision at the object boundary.\relax }}{1}{figure.caption.1}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{error_examples}{{1}{1}{Pink is the segmentation from individual workers. Blue solid line delineates the ground truth. The red boxed pointer indicates the task of interest shown to users. Examples demonstrating common error patterns among crowdsourced image segmentation, including 1) annotations on the wrong semantic object, 2) ambiguity in regional inclusion and exclusion, and 3) imprecision at the object boundary.\relax }{figure.caption.1}{}}
\citation{Torralba2010}
\citation{MartinFTM01}
\citation{Li2009}
\citation{Gurari2015}
\citation{Lin2014}
\citation{Everingham15}
\citation{Everingham15}
\citation{Sameki2015}
\citation{Gurari2016}
\citation{Song2018}
\citation{Russakovsky2015}
\citation{Gurari2016}
\citation{Vittayakorn2011}
\citation{Vittayakorn2011}
\citation{Cabezas2015}
\citation{Sameki2015}
\citation{Sorokin2008}
\citation{Vittayakorn2011}
\citation{Russakovsky2015}
\citation{Dawid1979}
\citation{OCWelinder2010}
\citation{MDWWelinder2010}
\newlabel{sec:related}{{2}{2}{Related Work}{section.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Related Work}{2}{section.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Flowchart summarizing the classes of existing algorithms for image segmentation (blue) and a novel class of algorithms proposed in this paper (yellow). Majority-vote (MV) is colored both blue and yellow, since a common algorithm in crowdsourcing literature, but have not been extensively applied to crowdsourced image segmentation.\relax }}{2}{figure.caption.2}}
\newlabel{flowchart}{{2}{2}{Flowchart summarizing the classes of existing algorithms for image segmentation (blue) and a novel class of algorithms proposed in this paper (yellow). Majority-vote (MV) is colored both blue and yellow, since a common algorithm in crowdsourcing literature, but have not been extensively applied to crowdsourced image segmentation.\relax }{figure.caption.2}{}}
\citation{Sameki2015}
\citation{Karger2013}
\citation{Lin2012}
\citation{Sorokin2008}
\citation{Lin2014}
\citation{Gurari2018}
\citation{Lin2014}
\citation{bell14intrinsic}
\citation{MDWWelinder2010}
\citation{Sorokin2008}
\citation{Lin2014}
\citation{Gurari2018}
\newlabel{sec:goal}{{3}{3}{Goal and Data}{section.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Goal and Data}{3}{section.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Goal}{3}{subsection.3.1}}
\@writefile{tdo}{\contentsline {todo}{Show one image + ground truth here}{3}{section*.3}}
\pgfsyspdfmark {pgfid1}{11380305}{11040277}
\newlabel{sec:data}{{3.2}{3}{Data Collection}{subsection.3.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Data Collection}{3}{subsection.3.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces An example interface for the segmentation webapp can be seen \href  {http://crowd-segment.herokuapp.com/segment/COCO_train2014_000000000127/10/}{here}.\relax }}{3}{figure.caption.4}}
\newlabel{interface}{{3}{3}{An example interface for the segmentation webapp can be seen \href {http://crowd-segment.herokuapp.com/segment/COCO_train2014_000000000127/10/}{here}.\relax }{figure.caption.4}{}}
\newlabel{sec:errors}{{3.3}{3}{Worker Error patterns}{subsection.3.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Worker Error patterns}{3}{subsection.3.3}}
\citation{felzenszwalb2004efficient}
\newlabel{sec:methods}{{4}{4}{Methods}{section.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Methods}{4}{section.4}}
\@writefile{tdo}{\contentsline {todo}{Give names to all methods that can be used in experiments section}{4}{section*.5}}
\pgfsyspdfmark {pgfid2}{11380305}{25655380}
\newlabel{sec:vision}{{4.1}{4}{Vision-based methods~}{subsection.4.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Vision-based methods\nobreakspace  {}}{4}{subsection.4.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Left: Raw image. Center: Vision tiles with $k=500$. Right: Vision tiles with $k=100$.\relax }}{4}{figure.caption.7}}
\newlabel{vision_example}{{4}{4}{Left: Raw image. Center: Vision tiles with $k=500$. Right: Vision tiles with $k=100$.\relax }{figure.caption.7}{}}
\@writefile{tdo}{\contentsline {todo}{img for ref segmentation overlaid on vision tiles (incorporate with Fig.\ref  {vision_example})}{4}{section*.6}}
\pgfsyspdfmark {pgfid3}{28845362}{20895102}
\newlabel{sec:crowd}{{4.2}{4}{Crowdsourcing methods~}{subsection.4.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Crowdsourcing methods\nobreakspace  {}}{4}{subsection.4.2}}
\citation{Vittayakorn2011}
\citation{segmentation-tr}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Left: Red boundaries shows the segmentation boundaries drawn by five workers overlaid on the image. Right: Segmentation boundaries still shown in red. The overlaid segmentation creates a masks where the color indicates the number of workers who voted for the tile region.\relax }}{5}{figure.caption.8}}
\newlabel{tile_demo}{{5}{5}{Left: Red boundaries shows the segmentation boundaries drawn by five workers overlaid on the image. Right: Segmentation boundaries still shown in red. The overlaid segmentation creates a masks where the color indicates the number of workers who voted for the tile region.\relax }{figure.caption.8}{}}
\newlabel{sec:agg-detailed}{{5}{5}{Aggregation Methods: A Closer Look~}{section.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Aggregation Methods: A Closer Look\nobreakspace  {}}{5}{section.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Majority Vote Aggregation (MV)}{5}{subsection.5.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Expectation-Maximization}{6}{subsection.5.2}}
\@writefile{tdo}{\contentsline {todo}{techreport}{6}{section*.9}}
\pgfsyspdfmark {pgfid4}{11380305}{39703845}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Greedy Tile Picking}{6}{subsection.5.3}}
\@writefile{tdo}{\contentsline {todo}{techreport}{6}{section*.10}}
\pgfsyspdfmark {pgfid5}{28845362}{44974299}
\@writefile{tdo}{\contentsline {todo}{techreport}{6}{section*.11}}
\pgfsyspdfmark {pgfid6}{28845362}{36185490}
\newlabel{sec:results}{{6}{6}{Results and Discussion}{section.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Results and Discussion}{6}{section.6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}Experimental Setup}{6}{subsection.6.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}Evaluation Metrics}{6}{subsection.6.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3}What is the difference in performance between retrieval and aggregation-based methods?}{6}{subsection.6.3}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Percentage change in Jaccard between 5 workers samples and 30 workers sample averages.\relax }}{7}{table.caption.13}}
\newlabel{workerScaling}{{1}{7}{Percentage change in Jaccard between 5 workers samples and 30 workers sample averages.\relax }{table.caption.13}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Jaccard performance comparison between best-performing algorithms from retrieval and aggregation-based methods, with clustering as a preprocessing step where possible. Color denotes the type of algorithm used.\relax }}{7}{figure.caption.12}}
\newlabel{retreival_vs_aggregation}{{6}{7}{Jaccard performance comparison between best-performing algorithms from retrieval and aggregation-based methods, with clustering as a preprocessing step where possible. Color denotes the type of algorithm used.\relax }{figure.caption.12}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.4}How well does the inferred worker qualities predict individual worker performance?}{7}{subsection.6.4}}
\@writefile{toc}{\contentsline {subparagraph}{Correlation of worker qualities against performance}{7}{section*.14}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Linear correlation of worker qualities against ground truth performance for different quality models across different number of workers (N). The lower worker samples exhibit lower $R^2$ due to the variance from smaller number of datapoints for each independent fit. \relax }}{7}{table.caption.15}}
\newlabel{correlation}{{2}{7}{Linear correlation of worker qualities against ground truth performance for different quality models across different number of workers (N). The lower worker samples exhibit lower $R^2$ due to the variance from smaller number of datapoints for each independent fit. \relax }{table.caption.15}{}}
\@writefile{toc}{\contentsline {subparagraph}{Best worker quality retrieval}{7}{section*.16}}
\citation{Gurari2015}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Summary of average performance across workers with clustering applied as preprocessing in all algorithms across different number of workers (N). wqr is the abbreviation for best worker quality retrieval methods.\relax }}{8}{table.caption.17}}
\newlabel{bigtable}{{3}{8}{Summary of average performance across workers with clustering applied as preprocessing in all algorithms across different number of workers (N). wqr is the abbreviation for best worker quality retrieval methods.\relax }{table.caption.17}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.5}How do different families of aggregation-based algorithms relate and compare?}{8}{subsection.6.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.6}How well does clustering resolve multiple perspectives of crowdworkers and improve quality evaluation algorithms?}{8}{subsection.6.6}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Example image showing clustering performed on the same object from Figure \ref  {error_examples}.\relax }}{8}{figure.caption.18}}
\newlabel{cluster_example}{{7}{8}{Example image showing clustering performed on the same object from Figure \ref {error_examples}.\relax }{figure.caption.18}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7}Conclusion}{8}{section.7}}
\bibstyle{named}
\bibdata{reference}
\bibcite{AdrianaKovashka2016}{\citeauthoryear {{Adriana Kovashka} \bgroup \em  et al.\egroup }{2016}}
\bibcite{segmentation-tr}{\citeauthoryear {Anonymous}{2018}}
\bibcite{bell14intrinsic}{\citeauthoryear {Bell \bgroup \em  et al.\egroup }{2014}}
\bibcite{bell15minc}{\citeauthoryear {Bell \bgroup \em  et al.\egroup }{2015}}
\bibcite{Cabezas2015}{\citeauthoryear {Cabezas \bgroup \em  et al.\egroup }{2015}}
\bibcite{Dawid1979}{\citeauthoryear {Dawid and Skene}{1979}}
\bibcite{Everingham15}{\citeauthoryear {Everingham \bgroup \em  et al.\egroup }{2015}}
\bibcite{felzenszwalb2004efficient}{\citeauthoryear {Felzenszwalb and Huttenlocher}{2004}}
\bibcite{Gurari2015}{\citeauthoryear {Gurari \bgroup \em  et al.\egroup }{2015}}
\bibcite{Gurari2016}{\citeauthoryear {Gurari \bgroup \em  et al.\egroup }{2016}}
\bibcite{Gurari2018}{\citeauthoryear {Gurari \bgroup \em  et al.\egroup }{2018}}
\bibcite{Irshad2014}{\citeauthoryear {Irshad and et. al.}{2014}}
\bibcite{Karger2013}{\citeauthoryear {Karger \bgroup \em  et al.\egroup }{2013}}
\bibcite{Li2009}{\citeauthoryear {Li \bgroup \em  et al.\egroup }{2009}}
\bibcite{Lin2012}{\citeauthoryear {Lin \bgroup \em  et al.\egroup }{2012}}
\bibcite{Lin2014}{\citeauthoryear {Lin \bgroup \em  et al.\egroup }{2014}}
\bibcite{MartinFTM01}{\citeauthoryear {Martin \bgroup \em  et al.\egroup }{2001}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Performance comparisons between averaging over experiments with clustering as a preprocessing step(dotted) and the unclustered cases(solid) for different algorithms.\relax }}{9}{figure.caption.19}}
\newlabel{cluster_effect}{{8}{9}{Performance comparisons between averaging over experiments with clustering as a preprocessing step(dotted) and the unclustered cases(solid) for different algorithms.\relax }{figure.caption.19}{}}
\bibcite{Russakovsky2015}{\citeauthoryear {Russakovsky \bgroup \em  et al.\egroup }{2015}}
\bibcite{Sameki2015}{\citeauthoryear {Sameki \bgroup \em  et al.\egroup }{2015}}
\bibcite{Song2018}{\citeauthoryear {Song \bgroup \em  et al.\egroup }{2018}}
\bibcite{Sorokin2008}{\citeauthoryear {Sorokin and Forsyth}{2008}}
\bibcite{Torralba2010}{\citeauthoryear {Torralba \bgroup \em  et al.\egroup }{2010}}
\bibcite{Vittayakorn2011}{\citeauthoryear {Vittayakorn and Hays}{2011}}
\bibcite{OCWelinder2010}{\citeauthoryear {Welinder and Perona}{2010a}}
\bibcite{MDWWelinder2010}{\citeauthoryear {Welinder \bgroup \em  et al.\egroup }{2010b}}
\bibcite{Yamaguchi2012}{\citeauthoryear {Yamaguchi}{2012}}
