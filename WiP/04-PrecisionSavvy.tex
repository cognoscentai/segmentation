\vspace{-15pt}
\section{Fixing Boundary Imperfections\label{precision}}%: Aggregation v.s. Retrieval Comparison}
% \subsection{Retrieval-based methods}
% This class of algorithms tries to identify good and bad workers, and then chooses the best worker segmentation as the output segmentation. In this paper, we look at two different ways of ranking workers and choosing the best worker. First, we use the {\em number of control points}, i.e. number of vertices in a worker's segmentation polygon to rank workers. This is a ranking scheme that~\cite{Vittayakorn2011} showed performs well in practice. Intuitively, workers that have used a larger number of points are likely to have been more precise, and provided a more complex and accurate segmentation. Other heuristic ranking scheme is described in more detail in our technical report~\cite{segmentation-tr}.
% \begin{figure}[h!]
% \vspace{-10pt}
% \centering
% \includegraphics[width=0.8\textwidth]{plots/precision_issue_tile_example.png}
% \caption{Left: Pink boundaries shows worker segmentations and blue delineates the ground truth. Right: Segmentation boundaries drawn by five workers shown in red. Overlaid segmentation creates a masks where the color indicates the number of workers who voted for the tile region.}
% \label{tile_demo}
% \end{figure}
% \vspace{-10pt}

% , where we logically overlay all workers' segmentations on top of each other, as illustrated in Figure \ref{tile_demo} right, to create non-overlapping discrete tile units. 
At the heart of our aggregation techniques is the ``tile'' data representation. A tile is the smallest non-overlapping discrete unit created by overlaying all workers' segmentations on top of each other. %with a certain probability of being contained in the ground truth segmentation. 
The tile formulation allow us to aggregate data from multiple workers, rather than being restricted to a single worker's segmentation---enabling the opportunity to fix one worker's errors via the help from another worker's segmentation (as shown in Figure \ref{tile_demo} right, both worker 1 and 2's segmentation can contribute towards the final segmentation).
\par This simple, but powerful idea of tiling also allows us to remodel our problem from that of ``generating a segmentation'' to a setting that is much more familiar to crowdsourcing researchers and practitioners. Since tiles are the lowest granularity units created by overlaying all workers' segmentations on top of each other, each tile is either completely contained in, or completely outside any given worker segmentation. Specifically, we can regard a worker segmentation as multiple boolean responses where they have voted ``yes'' or ``no'' to every tile independently. Intuitively, a worker   votes ``yes'' for every tile that is contained in their segmentation, and ``no'' for every tile that is not contained in their segmentation. As shown in Figure \ref{tile_demo} right, tile $t_2$ is voted ``yes'' by worker 1, 2, and 3; tile $t_3$ is voted ``yes'' by worker 2 and 3.  
\par Now, our problem of choosing a set of tiles to form a segmentation boils down to aggregating multiple boolean responses on every individual tile. Tiles with a final aggregated answer of ``yes'' are included in our output segmentation, while the remaining tiles are excluded. We should note that tiles need not necessarily be completely contained or completely outside the ground truth segmentation, therefore not every tile has a ground truth boolean answer. For tiles that are not completely contained or completely excluded in the ground truth, we gain recall but lose precision if we include them in our output segmentation, or lose recall and gain precision if we don't include them in our output segmentation. The goal of our aggregation algorithms, described below, is to pick a good set of tiles that effectively trade-off precision versus recall.
\dor{I think we can shorten this para by saying the goal is to aggregate boolean responses, we develop 3 classes of algo to do this below?}

% The intuition here is that by splitting the image into tiles, we get finer granularity information than by looking at complete segmentations. This also allows us to aggregate data from multiple workers rather than having to choose a single worker bounding box---enabling the opportunity to choose partial segmentations by fixing one worker's errors via the help from another worker's segmentation.
% Now, we will describe several algorithms for picking a good set of tiles.
%The goal of our aggregation algorithms, described below, is to pick a good set of tiles that effectively trade-off precision versus recall.
\stitle{Aggregation: Majority Vote Aggregation (MV)} 
\par \noindent Include a tile in the output segmentation if and only if the tile is voted by at least 50\% of all worker segmentations.

\stitle{Aggregation: Expectation-Maximization (EM)}
\par \noindent Unlike MV, which assumes that all workers performs uniformly, EM approaches use worker quality models to infer the likelihood that a tile is part of the ground truth segmentation. The EM algorithm simultaneously estimate both worker qualities and tile likelihoods as hidden variables. Our basic worker quality models the probability of the worker voting for a tile correctly. Another model variant accounts for tile areas, based on the intuition that workers should be penalized more if they made a mistake on a large tile (e.g. yellow tile in Figure \ref{tile_demo} middle) than if they made a mistake on one of the small tiles near the boundary. Our advanced 4-parameter Bernoulli worker quality model additionally accounts for true and false positive rates. Details of the formal derivation and worker quality models can be found in our technical report.

\stitle{Aggregation: Greedy Tile Picking (greedy)} 
%, and then picks tiles in that order, effectively picking tiles in order of their contribution to the Jaccard similarity against ground truth, 
\par \noindent The greedy algorithm picks tiles sorted in descending order based on their overlap area to non-overlap area ratio, for as long as the estimated Jaccard of the resulting segmentation continue to increase. Intuitively, tiles with high overlap area with ground truth and low non-overlap area contribute a lot to recall gain and very little to precision error. We include a proof in our technical report showing that picking tiles in the descending order of their overlap area to non-overlap ratio maximizes the Jaccard similarity of our segmentation locally at every step. The challenge here is that tile overlap and non-overlap areas are unknown, so we use tile-inclusion probabilities from EM to estimate these areas as a heuristic. Furthermore, since we cannot compute the actual Jaccard score against the hidden ground truth, we use a heuristic baseline like MV as a proxy for the ground truth.

\stitle{Retrieval: Number of Control Points (num pts)}
\par \noindent Pick the worker segmentation with the largest number of control points around the segmentation boundary (i.e. most precise drawing) as the output segmentation.

\begin{figure}[h!]
\centering
\includegraphics[width=0.9\textwidth]{plots/precision_issue_tile_example.pdf}
\caption{Left: Pink boundaries shows worker segmentations and blue delineates the ground truth. Middle: Segmentation boundaries drawn by five workers shown in red. Overlaid segmentation creates a masks where the color indicates the number of workers who voted for the tile region. Right: Toy example of tiles created by three worker's segmentation around a dumbell object delineated by the black dotted line.}
\label{tile_demo}
\setlength{\abovecaptionskip}{-10pt}
\setlength{\belowcaptionskip}{-30pt}
\end{figure}  