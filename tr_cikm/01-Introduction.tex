%!TEX root = main.tex
\section{Introduction\label{sec:intro}}

Precise, instance-level object segmentation is crucial for identifying and tracking objects in a variety of real-world emergent applications of autonomy, including robotics~\cite{Natonek1998}, image organization and retrieval~\cite{Yamaguchi2012}, and medicine~\cite{Irshad2014}. To this end, there has been a lot of work on employing crowdsourcing to generate training data for segmentation, including Pascal-VOC~\cite{Everingham15}, LabelMe~\cite{Torralba2010}, OpenSurfaces~\cite{bell15minc}, and MS-COCO~\cite{Lin2012}. Unfortunately, raw data collected from the crowd is known to be noisy due to varying degrees of worker skills, attention, and motivation~\cite{bell14intrinsic,MDWWelinder2010}. 
\par To deal with these challenges, many have employed heuristics indicative of crowdsourced segmentation quality to pick the best worker-provided segmentation~\cite{Sorokin2008,Vittayakorn2011}. However, this approach ends up discarding the majority of the worker segmentations and is limited by what the best worker can do. The contributions of this paper is as follows: 
\begin{itemize}
	\item We introduce a novel class of {\em aggregation-based} methods that incorporates portions of segmentations from multiple workers into a combined one described in Section~\ref{precision}. By overlaying worker segmentations on top of each other, we can decompose the image into non-overlapping tiles, where each tile has some workers who believe this tile belongs to the object, and others who do not. Each tile can be treated as an independent boolean question, deriving an answer from a worker---does this tile belong to the object or not, following which we may be able to apply Expectation-Maximization (EM)~\cite{Dawid1979} to derive maximum likelihood tiles and worker accuracies, a greedy approach for tile picking based on worker fraction votes, and simple majority vote aggregation. 
	\item To our surprise, despite the intuitive simplicity of aggregation-based methods, we have not seen this class of algorithms described or evaluated in prior work. We evaluate this class of algorithms against existing methods in Section~\ref{sec:experiment} and found that it performs much better than existing approaches
	\item We formally characterize the types of worker error in crowdsourced image segmentation in Section~\ref{sec:error} and describe a well-known multiple perspective issue in crowdsourced image segmentation~\cite{Sorokin2008,Lin2014,Guari2018}, where workers often segment the wrong objects or erroneously include or exclude large semantically-ambiguous portions of an object in the resulting segmentation.To address this issue, in Section~\ref{perspective}, we develop a clustering-based solution which can be applied as a preprocessing step to any quality evaluation methods.
	%Our analysis of common worker errors in crowdsourced segmentation shows that workers often segment the wrong objects or erroneously include or exclude large semantically-ambiguous portions of an object in the resulting segmentation. We discuss these semantic errors and ambiguities in Section~\ref{sec:error} and propose a clustering-based preprocessing technique that resolves such errors in Section~\ref{perspective}.
\end{itemize}
%different worker perspectives in multiple segmentations.}
%To resolve semantic ambiguity and mistakes commonly observed in crowdsourced segmentation, we propose a clustering-based preprocessing technique that resolves different worker perspectives in multiple segmentations. 
