\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{Natonek1998}
\citation{Yamaguchi2012}
\citation{Irshad2014}
\citation{Everingham15}
\citation{Torralba2010}
\citation{bell15minc}
\citation{Lin2012}
\citation{bell14intrinsic,MDWWelinder2010}
\citation{Sorokin2008,Vittayakorn2011}
\citation{Dawid1979}
\citation{Sorokin2008,Lin2014,Guari2018}
\citation{Vittayakorn2011,Russakovsky2015}
\citation{Cabezas2015,Sameki2015,Sorokin2008}
\citation{Sameki2015}
\citation{Lin2014,Everingham15}
\citation{Song2018}
\citation{Russakovsky2015,Gurari2016}
\@writefile{toc}{\contentsline {section}{Abstract}{1}{section*.1}}
\newlabel{sec:intro}{{1}{1}{Introduction}{section.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}}
\newlabel{sec:related}{{2}{1}{Related Work}{section.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Related Work}{1}{section.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Taxonomy of quality evaluation algorithms for crowdsourced segmentation, including existing methods (blue) and a novel class of algorithms proposed in this paper (yellow).\vspace  {-15pt}\relax }}{1}{figure.caption.3}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{flowchart}{{1}{1}{Taxonomy of quality evaluation algorithms for crowdsourced segmentation, including existing methods (blue) and a novel class of algorithms proposed in this paper (yellow).\vspace {-15pt}\relax }{figure.caption.3}{}}
\citation{felzenszwalb2004efficient,Y.Y.Boykov2001}
\citation{AdrianaKovashka2016,Lin2014,zhou2017scene}
\citation{Sorokin2008,Lin2014,Gurari2018}
\newlabel{sec:error}{{3}{2}{Error Analysis}{section.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Error Analysis}{2}{section.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Examples of common worker mistakes.\relax }}{2}{figure.caption.4}}
\newlabel{error_examples}{{2}{2}{Examples of common worker mistakes.\relax }{figure.caption.4}{}}
\newlabel{precision}{{4}{2}{Fixing Boundary Imperfections}{section.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Fixing Boundary Imperfections}{2}{section.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Tile Data Model}{2}{subsection.4.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Left: Toy example demonstrating tiles created by three workers' segmentations around a dumbell object delineated by the black dotted line. Right: Segmentation boundaries drawn by five workers shown in red. Overlaid segmentation creates a mask where the color indicates the number of workers who voted for the tile region.\relax }}{2}{figure.caption.5}}
\newlabel{tile_demo}{{3}{2}{Left: Toy example demonstrating tiles created by three workers' segmentations around a dumbell object delineated by the black dotted line. Right: Segmentation boundaries drawn by five workers shown in red. Overlaid segmentation creates a mask where the color indicates the number of workers who voted for the tile region.\relax }{figure.caption.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Majority Vote Aggregation (MV)}{3}{subsection.4.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Worker Quality-Aware Algorithms}{3}{subsection.4.3}}
\newlabel{objective}{{5}{3}{Worker Quality-Aware Algorithms}{equation.4.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}Inference}{3}{subsection.4.4}}
\@writefile{toc}{\contentsline {subsubsection}{NP-hardness proof}{4}{section*.6}}
\@writefile{toc}{\contentsline {subsubsection}{Expectation-Maximization (EM)}{4}{section*.7}}
\@writefile{toc}{\contentsline {subsubsection}{Proof:}{4}{section*.8}}
\@writefile{loa}{\contentsline {algocf}{\numberline {1}{\ignorespaces M step algorithm. For the initialization of $T^*$, we could start from either an empty set or a high-confidence tileset. The set of $\mathcal  {T}$ to chose from can either be the set of all tiles or all tiles adjacent to $T^*$. \relax }}{4}{algocf.1}}
\newlabel{Mstep}{{1}{4}{Proof:}{algocf.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{Greedy Tile Picking (greedy)}{4}{section*.10}}
\newlabel{perspective}{{5}{4}{Perspective Resolution}{section.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Perspective Resolution}{4}{section.5}}
\citation{Lin2014}
\citation{Cabezas2015,Sameki2015,Song2018,Lin2014}
\citation{Vittayakorn2011,Sorokin2008}
\citation{felzenszwalb2004efficient}
\citation{felzenszwalb2004efficient}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Example image showing clustering performed on the same object from Figure \ref  {error_examples} left and middle.\relax }}{5}{figure.caption.11}}
\newlabel{cluster_example}{{4}{5}{Example image showing clustering performed on the same object from Figure \ref {error_examples} left and middle.\relax }{figure.caption.11}{}}
\newlabel{sec:experiment_setup}{{6}{5}{Experimental Setup}{section.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Experimental Setup}{5}{section.6}}
\newlabel{dataset}{{6.1}{5}{Dataset Description}{subsection.6.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}Dataset Description}{5}{subsection.6.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}Evaluation Metrics}{5}{subsection.6.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Example of the vision color tiling for different chosen granularities. Left: Raw image. Vision segmentation with $k=100$(Center) and $k=500$ (Right). Vision tiles with a significant overlap area with the worker segmentation (white boundaries) is selected.\relax }}{5}{figure.caption.12}}
\newlabel{vision_example}{{5}{5}{Example of the vision color tiling for different chosen granularities. Left: Raw image. Vision segmentation with $k=100$(Center) and $k=500$ (Right). Vision tiles with a significant overlap area with the worker segmentation (white boundaries) is selected.\relax }{figure.caption.12}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3}Baseline Algorithms}{5}{subsection.6.3}}
\newlabel{sec:vision}{{6.3}{5}{Baseline Algorithms}{subsection.6.3}{}}
\newlabel{sec:experiment}{{7}{6}{Experimental Results}{section.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7}Experimental Results}{6}{section.7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1}Aggregation-based methods perform significantly better than retrieval-based methods (no clustering)}{6}{subsection.7.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Performance of the original algorithms that do not make use of ground truth information (Left) and ones that do (Right). MV and EM results are so close that they overlay on each other.\relax }}{6}{figure.caption.13}}
\newlabel{retrieval_vs_aggregation}{{6}{6}{Performance of the original algorithms that do not make use of ground truth information (Left) and ones that do (Right). MV and EM results are so close that they overlay on each other.\relax }{figure.caption.13}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2}The performance of aggregation-based methods scale well as more worker segmentations are added.}{6}{subsection.7.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.3}Clustering as preprocessing improves algorithmic performance.}{6}{subsection.7.3}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Jaccard percentage change due to worker scaling and clustering. Algorithms with * makes use of ground truth information.\relax }}{6}{table.caption.14}}
\newlabel{statsTable}{{1}{6}{Jaccard percentage change due to worker scaling and clustering. Algorithms with * makes use of ground truth information.\relax }{table.caption.14}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.4}Overall: with clustering + our algo > baseline}{6}{subsection.7.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.5}How well does the inferred worker qualities predict individual worker performance?}{6}{subsection.7.5}}
\@writefile{toc}{\contentsline {subsubsection}{Correlation of worker qualities against performance}{6}{section*.16}}
\bibstyle{ACM-Reference-Format}
\bibdata{reference}
\bibcite{AdrianaKovashka2016}{{1}{2016}{{{Adriana Kovashka} et~al\unhbox \voidb@x \hbox {.}}}{{{Adriana Kovashka}, {Olga Russakovsky}, and {Li Fei-Fei}}}}
\bibcite{bell14intrinsic}{{2}{2014}{{Bell et~al\unhbox \voidb@x \hbox {.}}}{{Bell, Bala, and Snavely}}}
\bibcite{bell15minc}{{3}{2015}{{Bell et~al\unhbox \voidb@x \hbox {.}}}{{Bell, Upchurch, Snavely, and Bala}}}
\bibcite{Cabezas2015}{{4}{2015}{{Cabezas et~al\unhbox \voidb@x \hbox {.}}}{{Cabezas, Carlier, Charvillat, Salvador, and Giro-I-Nieto}}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Performance comparisons between averaging over experiments with clustering as a preprocessing step(dotted) and the unclustered cases(solid) for different algorithms.\relax }}{7}{figure.caption.15}}
\newlabel{cluster_effect}{{7}{7}{Performance comparisons between averaging over experiments with clustering as a preprocessing step(dotted) and the unclustered cases(solid) for different algorithms.\relax }{figure.caption.15}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Linear correlation of worker qualities against ground truth performance for different quality models across different number of workers (N). The lower worker samples exhibit lower $R^2$ due to the variance from smaller number of datapoints for each independent fit. \relax }}{7}{table.caption.17}}
\newlabel{correlation}{{2}{7}{Linear correlation of worker qualities against ground truth performance for different quality models across different number of workers (N). The lower worker samples exhibit lower $R^2$ due to the variance from smaller number of datapoints for each independent fit. \relax }{table.caption.17}{}}
\@writefile{toc}{\contentsline {subsubsection}{Best worker quality retrieval}{7}{section*.18}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Summary of average performance across workers with clustering applied as preprocessing in all algorithms across different number of workers (N). wqr is the abbreviation for best worker quality retrieval methods.\relax }}{7}{table.caption.19}}
\newlabel{bigtable}{{3}{7}{Summary of average performance across workers with clustering applied as preprocessing in all algorithms across different number of workers (N). wqr is the abbreviation for best worker quality retrieval methods.\relax }{table.caption.19}{}}
\@writefile{toc}{\contentsline {section}{\numberline {8}Conclusion and Future Work}{7}{section.8}}
\@writefile{toc}{\contentsline {section}{References}{7}{section*.21}}
\bibcite{Dawid1979}{{5}{1979}{{Dawid and Skene}}{{Dawid and Skene}}}
\bibcite{Everingham15}{{6}{2015}{{Everingham et~al\unhbox \voidb@x \hbox {.}}}{{Everingham, Eslami, Van~Gool, Williams, Winn, and Zisserman}}}
\bibcite{felzenszwalb2004efficient}{{7}{2004}{{Felzenszwalb and Huttenlocher}}{{Felzenszwalb and Huttenlocher}}}
\bibcite{Gurari2018}{{8}{2018}{{Gurari et~al\unhbox \voidb@x \hbox {.}}}{{Gurari, He, Xiong, Zhang, Sameki, Jain, Sclaroff, Betke, and Grauman}}}
\bibcite{Gurari2016}{{9}{2016}{{Gurari et~al\unhbox \voidb@x \hbox {.}}}{{Gurari, Sameki, Wu, and Betke}}}
\bibcite{Irshad2014}{{10}{2014}{{Irshad and et. al.}}{{Irshad and et. al.}}}
\bibcite{Lin2012}{{11}{2012}{{Lin et~al\unhbox \voidb@x \hbox {.}}}{{Lin, Mausam, and Weld}}}
\bibcite{Lin2014}{{12}{2014}{{Lin et~al\unhbox \voidb@x \hbox {.}}}{{Lin, Maire, Belongie, Hays, Perona, Ramanan, Doll{\'{a}}r, and Zitnick}}}
\bibcite{Natonek1998}{{13}{1998}{{Natonek}}{{Natonek}}}
\bibcite{Russakovsky2015}{{14}{2015}{{Russakovsky et~al\unhbox \voidb@x \hbox {.}}}{{Russakovsky, Li, and Fei-Fei}}}
\bibcite{Sameki2015}{{15}{2015}{{Sameki et~al\unhbox \voidb@x \hbox {.}}}{{Sameki, Gurari, and Betke}}}
\bibcite{Song2018}{{16}{2018}{{Song et~al\unhbox \voidb@x \hbox {.}}}{{Song, Fok, Lundgard, Yang, Kim, and Lasecki}}}
\bibcite{Sorokin2008}{{17}{2008}{{Sorokin and Forsyth}}{{Sorokin and Forsyth}}}
\bibcite{Torralba2010}{{18}{2010}{{Torralba et~al\unhbox \voidb@x \hbox {.}}}{{Torralba, Russell, and Yuen}}}
\bibcite{Vittayakorn2011}{{19}{2011}{{Vittayakorn and Hays}}{{Vittayakorn and Hays}}}
\bibcite{MDWWelinder2010}{{20}{2010}{{Welinder et~al\unhbox \voidb@x \hbox {.}}}{{Welinder, Branson, Belongie, and Perona}}}
\bibcite{Yamaguchi2012}{{21}{2012}{{Yamaguchi}}{{Yamaguchi}}}
\bibcite{Y.Y.Boykov2001}{{22}{2001}{{Y.Y.Boykov and M-P.Jolly}}{{Y.Y.Boykov and M-P.Jolly}}}
\bibcite{zhou2017scene}{{23}{2017}{{Zhou et~al\unhbox \voidb@x \hbox {.}}}{{Zhou, Zhao, Puig, Fidler, Barriuso, and Torralba}}}
\newlabel{tocindent-1}{0pt}
\newlabel{tocindent0}{0pt}
\newlabel{tocindent1}{4.5pt}
\newlabel{tocindent2}{11.25pt}
\newlabel{tocindent3}{0pt}
\newlabel{TotPages}{{8}{8}{}{page.8}{}}
